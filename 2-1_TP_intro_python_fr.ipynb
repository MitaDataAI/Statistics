{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "586c7b61-c116-46d2-a1b4-68073878763e",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9b779ac3-216e-4923-b8fe-f20279ddc706",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from os import mkdir\n",
    "import string\n",
    "from collections import Counter \n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ed6b3ee-823f-4b8b-96ae-b89a58e28324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function mkdir in module nt:\n",
      "\n",
      "mkdir(path, mode=511, *, dir_fd=None)\n",
      "    Create a directory.\n",
      "    \n",
      "    If dir_fd is not None, it should be a file descriptor open to a directory,\n",
      "      and path should be relative; path will then be relative to that directory.\n",
      "    dir_fd may not be implemented on your platform.\n",
      "      If it is unavailable, using it will raise a NotImplementedError.\n",
      "    \n",
      "    The mode argument is ignored on Windows.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m\n",
       "\u001b[0mlinear_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mfit_intercept\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcopy_X\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mpositive\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "Ordinary least squares Linear Regression.\n",
       "\n",
       "LinearRegression fits a linear model with coefficients w = (w1, ..., wp)\n",
       "to minimize the residual sum of squares between the observed targets in\n",
       "the dataset, and the targets predicted by the linear approximation.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "fit_intercept : bool, default=True\n",
       "    Whether to calculate the intercept for this model. If set\n",
       "    to False, no intercept will be used in calculations\n",
       "    (i.e. data is expected to be centered).\n",
       "\n",
       "copy_X : bool, default=True\n",
       "    If True, X will be copied; else, it may be overwritten.\n",
       "\n",
       "n_jobs : int, default=None\n",
       "    The number of jobs to use for the computation. This will only provide\n",
       "    speedup in case of sufficiently large problems, that is if firstly\n",
       "    `n_targets > 1` and secondly `X` is sparse or if `positive` is set\n",
       "    to `True`. ``None`` means 1 unless in a\n",
       "    :obj:`joblib.parallel_backend` context. ``-1`` means using all\n",
       "    processors. See :term:`Glossary <n_jobs>` for more details.\n",
       "\n",
       "positive : bool, default=False\n",
       "    When set to ``True``, forces the coefficients to be positive. This\n",
       "    option is only supported for dense arrays.\n",
       "\n",
       "    .. versionadded:: 0.24\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "coef_ : array of shape (n_features, ) or (n_targets, n_features)\n",
       "    Estimated coefficients for the linear regression problem.\n",
       "    If multiple targets are passed during the fit (y 2D), this\n",
       "    is a 2D array of shape (n_targets, n_features), while if only\n",
       "    one target is passed, this is a 1D array of length n_features.\n",
       "\n",
       "rank_ : int\n",
       "    Rank of matrix `X`. Only available when `X` is dense.\n",
       "\n",
       "singular_ : array of shape (min(X, y),)\n",
       "    Singular values of `X`. Only available when `X` is dense.\n",
       "\n",
       "intercept_ : float or array of shape (n_targets,)\n",
       "    Independent term in the linear model. Set to 0.0 if\n",
       "    `fit_intercept = False`.\n",
       "\n",
       "n_features_in_ : int\n",
       "    Number of features seen during :term:`fit`.\n",
       "\n",
       "    .. versionadded:: 0.24\n",
       "\n",
       "feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
       "    Names of features seen during :term:`fit`. Defined only when `X`\n",
       "    has feature names that are all strings.\n",
       "\n",
       "    .. versionadded:: 1.0\n",
       "\n",
       "See Also\n",
       "--------\n",
       "Ridge : Ridge regression addresses some of the\n",
       "    problems of Ordinary Least Squares by imposing a penalty on the\n",
       "    size of the coefficients with l2 regularization.\n",
       "Lasso : The Lasso is a linear model that estimates\n",
       "    sparse coefficients with l1 regularization.\n",
       "ElasticNet : Elastic-Net is a linear regression\n",
       "    model trained with both l1 and l2 -norm regularization of the\n",
       "    coefficients.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "From the implementation point of view, this is just plain Ordinary\n",
       "Least Squares (scipy.linalg.lstsq) or Non Negative Least Squares\n",
       "(scipy.optimize.nnls) wrapped as a predictor object.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> import numpy as np\n",
       ">>> from sklearn.linear_model import LinearRegression\n",
       ">>> X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\n",
       ">>> # y = 1 * x_0 + 2 * x_1 + 3\n",
       ">>> y = np.dot(X, np.array([1, 2])) + 3\n",
       ">>> reg = LinearRegression().fit(X, y)\n",
       ">>> reg.score(X, y)\n",
       "1.0\n",
       ">>> reg.coef_\n",
       "array([1., 2.])\n",
       ">>> reg.intercept_\n",
       "np.float64(3.0...)\n",
       ">>> reg.predict(np.array([[3, 5]]))\n",
       "array([16.])\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\users\\mita\\anaconda3\\envs\\portofolio\\lib\\site-packages\\sklearn\\linear_model\\_base.py\n",
       "\u001b[1;31mType:\u001b[0m           ABCMeta\n",
       "\u001b[1;31mSubclasses:\u001b[0m     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "help (mkdir)\n",
    "linear_model.LinearRegression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0a992af-84c0-4a7f-9241-387f5c5f5948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.2\n"
     ]
    }
   ],
   "source": [
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc9b41fe-d802-494b-9e15-1bab60523d82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['class LinearRegression(MultiOutputMixin, RegressorMixin, LinearModel):\\n',\n",
       "  '    \"\"\"\\n',\n",
       "  '    Ordinary least squares Linear Regression.\\n',\n",
       "  '\\n',\n",
       "  '    LinearRegression fits a linear model with coefficients w = (w1, ..., wp)\\n',\n",
       "  '    to minimize the residual sum of squares between the observed targets in\\n',\n",
       "  '    the dataset, and the targets predicted by the linear approximation.\\n',\n",
       "  '\\n',\n",
       "  '    Parameters\\n',\n",
       "  '    ----------\\n',\n",
       "  '    fit_intercept : bool, default=True\\n',\n",
       "  '        Whether to calculate the intercept for this model. If set\\n',\n",
       "  '        to False, no intercept will be used in calculations\\n',\n",
       "  '        (i.e. data is expected to be centered).\\n',\n",
       "  '\\n',\n",
       "  '    copy_X : bool, default=True\\n',\n",
       "  '        If True, X will be copied; else, it may be overwritten.\\n',\n",
       "  '\\n',\n",
       "  '    n_jobs : int, default=None\\n',\n",
       "  '        The number of jobs to use for the computation. This will only provide\\n',\n",
       "  '        speedup in case of sufficiently large problems, that is if firstly\\n',\n",
       "  '        `n_targets > 1` and secondly `X` is sparse or if `positive` is set\\n',\n",
       "  '        to `True`. ``None`` means 1 unless in a\\n',\n",
       "  '        :obj:`joblib.parallel_backend` context. ``-1`` means using all\\n',\n",
       "  '        processors. See :term:`Glossary <n_jobs>` for more details.\\n',\n",
       "  '\\n',\n",
       "  '    positive : bool, default=False\\n',\n",
       "  '        When set to ``True``, forces the coefficients to be positive. This\\n',\n",
       "  '        option is only supported for dense arrays.\\n',\n",
       "  '\\n',\n",
       "  '        .. versionadded:: 0.24\\n',\n",
       "  '\\n',\n",
       "  '    Attributes\\n',\n",
       "  '    ----------\\n',\n",
       "  '    coef_ : array of shape (n_features, ) or (n_targets, n_features)\\n',\n",
       "  '        Estimated coefficients for the linear regression problem.\\n',\n",
       "  '        If multiple targets are passed during the fit (y 2D), this\\n',\n",
       "  '        is a 2D array of shape (n_targets, n_features), while if only\\n',\n",
       "  '        one target is passed, this is a 1D array of length n_features.\\n',\n",
       "  '\\n',\n",
       "  '    rank_ : int\\n',\n",
       "  '        Rank of matrix `X`. Only available when `X` is dense.\\n',\n",
       "  '\\n',\n",
       "  '    singular_ : array of shape (min(X, y),)\\n',\n",
       "  '        Singular values of `X`. Only available when `X` is dense.\\n',\n",
       "  '\\n',\n",
       "  '    intercept_ : float or array of shape (n_targets,)\\n',\n",
       "  '        Independent term in the linear model. Set to 0.0 if\\n',\n",
       "  '        `fit_intercept = False`.\\n',\n",
       "  '\\n',\n",
       "  '    n_features_in_ : int\\n',\n",
       "  '        Number of features seen during :term:`fit`.\\n',\n",
       "  '\\n',\n",
       "  '        .. versionadded:: 0.24\\n',\n",
       "  '\\n',\n",
       "  '    feature_names_in_ : ndarray of shape (`n_features_in_`,)\\n',\n",
       "  '        Names of features seen during :term:`fit`. Defined only when `X`\\n',\n",
       "  '        has feature names that are all strings.\\n',\n",
       "  '\\n',\n",
       "  '        .. versionadded:: 1.0\\n',\n",
       "  '\\n',\n",
       "  '    See Also\\n',\n",
       "  '    --------\\n',\n",
       "  '    Ridge : Ridge regression addresses some of the\\n',\n",
       "  '        problems of Ordinary Least Squares by imposing a penalty on the\\n',\n",
       "  '        size of the coefficients with l2 regularization.\\n',\n",
       "  '    Lasso : The Lasso is a linear model that estimates\\n',\n",
       "  '        sparse coefficients with l1 regularization.\\n',\n",
       "  '    ElasticNet : Elastic-Net is a linear regression\\n',\n",
       "  '        model trained with both l1 and l2 -norm regularization of the\\n',\n",
       "  '        coefficients.\\n',\n",
       "  '\\n',\n",
       "  '    Notes\\n',\n",
       "  '    -----\\n',\n",
       "  '    From the implementation point of view, this is just plain Ordinary\\n',\n",
       "  '    Least Squares (scipy.linalg.lstsq) or Non Negative Least Squares\\n',\n",
       "  '    (scipy.optimize.nnls) wrapped as a predictor object.\\n',\n",
       "  '\\n',\n",
       "  '    Examples\\n',\n",
       "  '    --------\\n',\n",
       "  '    >>> import numpy as np\\n',\n",
       "  '    >>> from sklearn.linear_model import LinearRegression\\n',\n",
       "  '    >>> X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\\n',\n",
       "  '    >>> # y = 1 * x_0 + 2 * x_1 + 3\\n',\n",
       "  '    >>> y = np.dot(X, np.array([1, 2])) + 3\\n',\n",
       "  '    >>> reg = LinearRegression().fit(X, y)\\n',\n",
       "  '    >>> reg.score(X, y)\\n',\n",
       "  '    1.0\\n',\n",
       "  '    >>> reg.coef_\\n',\n",
       "  '    array([1., 2.])\\n',\n",
       "  '    >>> reg.intercept_\\n',\n",
       "  '    np.float64(3.0...)\\n',\n",
       "  '    >>> reg.predict(np.array([[3, 5]]))\\n',\n",
       "  '    array([16.])\\n',\n",
       "  '    \"\"\"\\n',\n",
       "  '\\n',\n",
       "  '    _parameter_constraints: dict = {\\n',\n",
       "  '        \"fit_intercept\": [\"boolean\"],\\n',\n",
       "  '        \"copy_X\": [\"boolean\"],\\n',\n",
       "  '        \"n_jobs\": [None, Integral],\\n',\n",
       "  '        \"positive\": [\"boolean\"],\\n',\n",
       "  '    }\\n',\n",
       "  '\\n',\n",
       "  '    def __init__(\\n',\n",
       "  '        self,\\n',\n",
       "  '        *,\\n',\n",
       "  '        fit_intercept=True,\\n',\n",
       "  '        copy_X=True,\\n',\n",
       "  '        n_jobs=None,\\n',\n",
       "  '        positive=False,\\n',\n",
       "  '    ):\\n',\n",
       "  '        self.fit_intercept = fit_intercept\\n',\n",
       "  '        self.copy_X = copy_X\\n',\n",
       "  '        self.n_jobs = n_jobs\\n',\n",
       "  '        self.positive = positive\\n',\n",
       "  '\\n',\n",
       "  '    @_fit_context(prefer_skip_nested_validation=True)\\n',\n",
       "  '    def fit(self, X, y, sample_weight=None):\\n',\n",
       "  '        \"\"\"\\n',\n",
       "  '        Fit linear model.\\n',\n",
       "  '\\n',\n",
       "  '        Parameters\\n',\n",
       "  '        ----------\\n',\n",
       "  '        X : {array-like, sparse matrix} of shape (n_samples, n_features)\\n',\n",
       "  '            Training data.\\n',\n",
       "  '\\n',\n",
       "  '        y : array-like of shape (n_samples,) or (n_samples, n_targets)\\n',\n",
       "  \"            Target values. Will be cast to X's dtype if necessary.\\n\",\n",
       "  '\\n',\n",
       "  '        sample_weight : array-like of shape (n_samples,), default=None\\n',\n",
       "  '            Individual weights for each sample.\\n',\n",
       "  '\\n',\n",
       "  '            .. versionadded:: 0.17\\n',\n",
       "  '               parameter *sample_weight* support to LinearRegression.\\n',\n",
       "  '\\n',\n",
       "  '        Returns\\n',\n",
       "  '        -------\\n',\n",
       "  '        self : object\\n',\n",
       "  '            Fitted Estimator.\\n',\n",
       "  '        \"\"\"\\n',\n",
       "  '        n_jobs_ = self.n_jobs\\n',\n",
       "  '\\n',\n",
       "  '        accept_sparse = False if self.positive else [\"csr\", \"csc\", \"coo\"]\\n',\n",
       "  '\\n',\n",
       "  '        X, y = validate_data(\\n',\n",
       "  '            self,\\n',\n",
       "  '            X,\\n',\n",
       "  '            y,\\n',\n",
       "  '            accept_sparse=accept_sparse,\\n',\n",
       "  '            y_numeric=True,\\n',\n",
       "  '            multi_output=True,\\n',\n",
       "  '            force_writeable=True,\\n',\n",
       "  '        )\\n',\n",
       "  '\\n',\n",
       "  '        has_sw = sample_weight is not None\\n',\n",
       "  '        if has_sw:\\n',\n",
       "  '            sample_weight = _check_sample_weight(\\n',\n",
       "  '                sample_weight, X, dtype=X.dtype, ensure_non_negative=True\\n',\n",
       "  '            )\\n',\n",
       "  '\\n',\n",
       "  '        # Note that neither _rescale_data nor the rest of the fit method of\\n',\n",
       "  '        # LinearRegression can benefit from in-place operations when X is a\\n',\n",
       "  \"        # sparse matrix. Therefore, let's not copy X when it is sparse.\\n\",\n",
       "  '        copy_X_in_preprocess_data = self.copy_X and not sp.issparse(X)\\n',\n",
       "  '\\n',\n",
       "  '        X, y, X_offset, y_offset, X_scale = _preprocess_data(\\n',\n",
       "  '            X,\\n',\n",
       "  '            y,\\n',\n",
       "  '            fit_intercept=self.fit_intercept,\\n',\n",
       "  '            copy=copy_X_in_preprocess_data,\\n',\n",
       "  '            sample_weight=sample_weight,\\n',\n",
       "  '        )\\n',\n",
       "  '\\n',\n",
       "  '        if has_sw:\\n',\n",
       "  '            # Sample weight can be implemented via a simple rescaling. Note\\n',\n",
       "  '            # that we safely do inplace rescaling when _preprocess_data has\\n',\n",
       "  '            # already made a copy if requested.\\n',\n",
       "  '            X, y, sample_weight_sqrt = _rescale_data(\\n',\n",
       "  '                X, y, sample_weight, inplace=copy_X_in_preprocess_data\\n',\n",
       "  '            )\\n',\n",
       "  '\\n',\n",
       "  '        if self.positive:\\n',\n",
       "  '            if y.ndim < 2:\\n',\n",
       "  '                self.coef_ = optimize.nnls(X, y)[0]\\n',\n",
       "  '            else:\\n',\n",
       "  '                # scipy.optimize.nnls cannot handle y with shape (M, K)\\n',\n",
       "  '                outs = Parallel(n_jobs=n_jobs_)(\\n',\n",
       "  '                    delayed(optimize.nnls)(X, y[:, j]) for j in range(y.shape[1])\\n',\n",
       "  '                )\\n',\n",
       "  '                self.coef_ = np.vstack([out[0] for out in outs])\\n',\n",
       "  '        elif sp.issparse(X):\\n',\n",
       "  '            X_offset_scale = X_offset / X_scale\\n',\n",
       "  '\\n',\n",
       "  '            if has_sw:\\n',\n",
       "  '\\n',\n",
       "  '                def matvec(b):\\n',\n",
       "  '                    return X.dot(b) - sample_weight_sqrt * b.dot(X_offset_scale)\\n',\n",
       "  '\\n',\n",
       "  '                def rmatvec(b):\\n',\n",
       "  '                    return X.T.dot(b) - X_offset_scale * b.dot(sample_weight_sqrt)\\n',\n",
       "  '\\n',\n",
       "  '            else:\\n',\n",
       "  '\\n',\n",
       "  '                def matvec(b):\\n',\n",
       "  '                    return X.dot(b) - b.dot(X_offset_scale)\\n',\n",
       "  '\\n',\n",
       "  '                def rmatvec(b):\\n',\n",
       "  '                    return X.T.dot(b) - X_offset_scale * b.sum()\\n',\n",
       "  '\\n',\n",
       "  '            X_centered = sparse.linalg.LinearOperator(\\n',\n",
       "  '                shape=X.shape, matvec=matvec, rmatvec=rmatvec\\n',\n",
       "  '            )\\n',\n",
       "  '\\n',\n",
       "  '            if y.ndim < 2:\\n',\n",
       "  '                self.coef_ = lsqr(X_centered, y)[0]\\n',\n",
       "  '            else:\\n',\n",
       "  '                # sparse_lstsq cannot handle y with shape (M, K)\\n',\n",
       "  '                outs = Parallel(n_jobs=n_jobs_)(\\n',\n",
       "  '                    delayed(lsqr)(X_centered, y[:, j].ravel())\\n',\n",
       "  '                    for j in range(y.shape[1])\\n',\n",
       "  '                )\\n',\n",
       "  '                self.coef_ = np.vstack([out[0] for out in outs])\\n',\n",
       "  '        else:\\n',\n",
       "  '            # cut-off ratio for small singular values\\n',\n",
       "  '            cond = max(X.shape) * np.finfo(X.dtype).eps\\n',\n",
       "  '            self.coef_, _, self.rank_, self.singular_ = linalg.lstsq(X, y, cond=cond)\\n',\n",
       "  '            self.coef_ = self.coef_.T\\n',\n",
       "  '\\n',\n",
       "  '        if y.ndim == 1:\\n',\n",
       "  '            self.coef_ = np.ravel(self.coef_)\\n',\n",
       "  '        self._set_intercept(X_offset, y_offset, X_scale)\\n',\n",
       "  '        return self\\n',\n",
       "  '\\n',\n",
       "  '    def __sklearn_tags__(self):\\n',\n",
       "  '        tags = super().__sklearn_tags__()\\n',\n",
       "  '        tags.input_tags.sparse = not self.positive\\n',\n",
       "  '        return tags\\n'],\n",
       " 457)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from inspect import getsourcelines # obtenir le code source de fonctions\n",
    "getsourcelines(linear_model.LinearRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24d31750-f880-40c0-9aa6-16ff7e524093",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9114f0d-48af-44e2-8c91-a9edc0ae79ef",
   "metadata": {},
   "source": [
    "# 1.  Introduction à Python, Numpy et Scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b9d485-9378-4541-8d44-2889ea67d0c7",
   "metadata": {},
   "source": [
    "## Nextpower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2bf2349-64ed-43c3-843b-fcf6d7171eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1\n",
    "def nextpower(n, m = 0):\n",
    "    while 2**m  < n :\n",
    "        m += 1\n",
    "    return(2**m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04365864-e09c-45c2-98a7-de7c7bc06c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2\n",
    "def nextpowerbis(n):\n",
    "    \"\"\"Compute the next power of 2 of n.\"\"\"\n",
    "    sol = 1\n",
    "    while sol < n:\n",
    "        sol *= 2\n",
    "    return sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7c40d84-9f4b-4ad8-ae2f-bd1b43758f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "print(nextpower(5))\n",
    "print(nextpowerbis(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b942687e-a4f0-49b8-b540-5ca05ff9a971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17592186044416\n",
      "0.0009975433349609375\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print(nextpower(10000000000000))\n",
    "print(time.time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b44c364e-2f1e-4719-99bc-9f09aadc9e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17592186044416\n",
      "0.0014188289642333984\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print(nextpowerbis(10000000000000))\n",
    "print(time.time() - t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837b66f4-4a92-466c-b221-d938ea296328",
   "metadata": {},
   "source": [
    "## Génération mot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fad9f071-fc82-4d22-95e0-228c8e4af232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcdefghijklmnopqrstuvwxyz\n"
     ]
    }
   ],
   "source": [
    "alphabet = string.ascii_lowercase\n",
    "print(alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af3f52b0-69a3-41d1-814a-a774fff1ac13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cfilorux'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate cfilorux\n",
    "x = slice(2, -1, 3)\n",
    "alphabet[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "968a3adb-d856-44a7-bca2-1cb088d162d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vxz'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate vxz : method 1\n",
    "x = slice(21, 26, 2)\n",
    "alphabet[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7cd83406-9d47-430b-81d5-3f273c2b4d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vxz\n"
     ]
    }
   ],
   "source": [
    "# Generate vxz : method 2\n",
    "print(alphabet[-5::2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "067e7c54-fa6e-4291-8b3e-6f9227669747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vxz\n"
     ]
    }
   ],
   "source": [
    "# Generate vxz : method 3\n",
    "alphabet_list = list(alphabet)\n",
    "index_v = alphabet_list.index('v')\n",
    "index_x = alphabet_list.index('x')\n",
    "index_z = alphabet_list.index('z')\n",
    "vzx = alphabet_list[index_v] + alphabet_list[index_x] + alphabet_list[index_z]\n",
    "print(vzx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a87e7d-1c7c-493c-a86c-6b5d838062cd",
   "metadata": {},
   "source": [
    "## Pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7612c161-0a10-4ce9-846a-ac8ca906dd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pi with 9 decimals: 3.141592654\n"
     ]
    }
   ],
   "source": [
    "print(\"Pi with 9 decimals:\", round(math.pi, 9))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e7f009-6226-4572-a0ba-99617c4c070c",
   "metadata": {},
   "source": [
    "## Count occurences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6518f065-c943-4449-a98f-9f2eade9ab23",
   "metadata": {},
   "outputs": [],
   "source": [
    "s=\"HelLo WorLd!!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "014ea78e-99fe-4cae-8ea5-40d2c12af84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'L': 2, 'o': 2, '!': 2, 'H': 1, 'e': 1, 'l': 1, ' ': 1, 'W': 1, 'r': 1, 'd': 1})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266574a2-54e2-4f29-944a-a8d8f10e0d07",
   "metadata": {},
   "source": [
    "## shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a76a9bc2-9200-4a9c-8721-615bba54661d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['y', 'v', 'z', 'u', 'w', 'g', 'k', 't', 'o', 'r', 'j', 'l', 'p', 'q', 'm', 'n', 's', 'd', 'a', 'x', 'f', 'b', 'e', 'i', 'h', 'c']\n"
     ]
    }
   ],
   "source": [
    "# Try shuffle\n",
    "shuffle(alphabet_list)\n",
    "print(alphabet_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "985ede13-11c9-47c0-a6bc-0da793df2b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 21, 7, 14, 18, 2, 3, 4, 22, 8, 5, 24, 19, 9, 10, 13, 12, 23, 17, 6, 25, 11, 15, 16, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "# Try shuffle to index\n",
    "indexes = list(range(len(alphabet)))\n",
    "shuffle(indexes)\n",
    "print(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "0be4e41c-5e2a-4819-a3e9-cc0ba7e912ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coding(message, rosette, alphabet):\n",
    "    \"\"\"encodage\"\"\"\n",
    "    message_coded = \"\"\n",
    "    for i, letter in enumerate(message):\n",
    "        if letter in alphabet:\n",
    "            message_coded += rosette[letter]\n",
    "        else:\n",
    "            message_coded += letter\n",
    "    message_coded = message_coded\n",
    "    return message_coded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "dea761ca-abfa-4970-a1ff-1f32a97a2f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 'u', 'b': 'v', 'c': 'h', 'd': 'o', 'e': 's', 'f': 'c', 'g': 'd', 'h': 'e', 'i': 'w', 'j': 'i', 'k': 'f', 'l': 'y', 'm': 't', 'n': 'j', 'o': 'k', 'p': 'n', 'q': 'm', 'r': 'x', 's': 'r', 't': 'g', 'u': 'z', 'v': 'l', 'w': 'p', 'x': 'q', 'y': 'a', 'z': 'b', ' ': ' '}\n",
      "{'u': 'a', 'v': 'b', 'h': 'c', 'o': 'd', 's': 'e', 'c': 'f', 'd': 'g', 'e': 'h', 'w': 'i', 'i': 'j', 'f': 'k', 'y': 'l', 't': 'm', 'j': 'n', 'k': 'o', 'n': 'p', 'm': 'q', 'x': 'r', 'r': 's', 'g': 't', 'z': 'u', 'l': 'v', 'p': 'w', 'q': 'x', 'a': 'y', 'b': 'z', ' ': ' '}\n"
     ]
    }
   ],
   "source": [
    "rosette_forward = {}\n",
    "rosette_backward = {}\n",
    "\n",
    "for i, letter in enumerate(alphabet):\n",
    "    rosette_forward[letter] = alphabet[indexes[i]]\n",
    "    rosette_backward[alphabet[indexes[i]]] = letter\n",
    "\n",
    "rosette_forward[\" \"] = \" \"\n",
    "rosette_backward[\" \"] = \" \"\n",
    "\n",
    "print(rosette_forward)\n",
    "print(rosette_backward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "4141276e-83de-420f-ad5f-bfd195bd3db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = \"Le monde n'est pas à l'abri d'une gouvernance par le robot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "f3adf6f6-686f-44c9-ac59-2a9bece4a22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message original:\n",
      "Le monde n'est pas à l'abri d'une gouvernance par le robot\n",
      "\n",
      "Message codé:\n",
      "Ls tkjos j'srg nur à y'uvxw o'zjs dkzlsxjujhs nux ys xkvkg\n",
      "\n",
      "Message décodé:\n",
      "Le monde n'est pas à l'abri d'une gouvernance par le robot\n",
      "\n",
      "Est ce que le message décodé est identique à l'original? True\n"
     ]
    }
   ],
   "source": [
    "# message = \"Tu les crois malades ?\".decode('utf8')\n",
    "print(\"Message original:\\n\" + message + \"\\n\")\n",
    "message_encoded = coding(message, rosette_forward, alphabet)\n",
    "print(\"Message codé:\" + \"\\n\"+ message_encoded + \"\\n\")\n",
    "message_decoded = coding(message_encoded, rosette_backward, alphabet)\n",
    "print(\"Message décodé:\" + \"\\n\"+ message_decoded  + \"\\n\")\n",
    "print(\"Est ce que le message décodé est identique à l'original? \" + str(message_decoded==message))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a749e7-16a7-4ac9-abb4-d9c70e8dc590",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (portofolio)",
   "language": "python",
   "name": "portofolio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
